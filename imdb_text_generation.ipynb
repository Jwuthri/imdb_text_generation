{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "from fastai.text import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Language Model Fine-tuning on IMDB Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[WindowsPath('C:/Users/Oren/.fastai/data/imdb/imdb.vocab'),\n",
       " WindowsPath('C:/Users/Oren/.fastai/data/imdb/imdb_databunch'),\n",
       " WindowsPath('C:/Users/Oren/.fastai/data/imdb/imdb_gen_databunch'),\n",
       " WindowsPath('C:/Users/Oren/.fastai/data/imdb/imdb_pos_databunch'),\n",
       " WindowsPath('C:/Users/Oren/.fastai/data/imdb/models'),\n",
       " WindowsPath('C:/Users/Oren/.fastai/data/imdb/README'),\n",
       " WindowsPath('C:/Users/Oren/.fastai/data/imdb/test'),\n",
       " WindowsPath('C:/Users/Oren/.fastai/data/imdb/tmp_clas'),\n",
       " WindowsPath('C:/Users/Oren/.fastai/data/imdb/tmp_lm'),\n",
       " WindowsPath('C:/Users/Oren/.fastai/data/imdb/train'),\n",
       " WindowsPath('C:/Users/Oren/.fastai/data/imdb/unsup')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get data, set up weights and vocab paths\n",
    "path = untar_data(URLs.IMDB)\n",
    "name = 'imdb_gen'\n",
    "lm_fns = [f'{name}_wts', f'{name}_vocab']\n",
    "path.ls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare the databunch\n",
    "bs=64\n",
    "### comment below after you run it for the first time\n",
    "data = (TextList.from_folder(path)\n",
    "           #Inputs: all the text files in path\n",
    "            .filter_by_folder(include=['train', 'test', 'unsup']) \n",
    "           #We may have other temp folders that contain text files so we only keep what's in train and test\n",
    "            .split_by_rand_pct(0.1, seed=42)\n",
    "           #We randomly split and keep 10% (10,000 reviews) for validation\n",
    "            .label_for_lm()           \n",
    "           #We want to do a language model so we label accordingly\n",
    "            .databunch(bs=bs))\n",
    "data.save(f'{name}_databunch')\n",
    "len(data.vocab.itos),len(data.train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>idx</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>later , by which time i did not care . xxmaj the character we should really care about is a very cocky , overconfident xxmaj ashton xxmaj kutcher . xxmaj the problem is he comes off as kid who thinks he 's better than anyone else around him and shows no signs of a cluttered closet . xxmaj his only obstacle appears to be winning over xxmaj costner . xxmaj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>sidebar , xxmaj swayze 's character who is no xxmaj monk ( ! ) has sired a xxmaj russian beauty xxmaj elena ( played by the gorgeous xxmaj marta xxmaj xxunk ) on his previous missions to the former xxmaj commie state . xxmaj xxunk xxmaj swayze does a passable job in setting out to defeat the evil xxmaj russians . xxmaj but young unknown actress xxmaj marta xxmaj xxunk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>proper sentences . \\n \\n  xxmaj in short i absolutely hated everything about this movie and not in \" so bad its good \" kinda way ... \\n \\n  xxmaj it was unadulterated drek . \\n \\n  xxmaj gavin xxbos xxup ok , let me start off by saying this is n't a horrible movie by any means . xxmaj it 's just not good . i</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3 . xxup if your not happy all the time , you are a bad person . xxmaj no one seems to show any other emotion but happiness , no matter which situation they are in . xxmaj if the child 's parents get mad or sad for some reason , the child may think of xxmaj mommy or xxmaj daddy differently . xxmaj not a good message at all</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>bad performances from all the huge stars . xxmaj the jokes ai n't funny , the lines are absurd and sometimes , they does n't make sense at all . xxmaj in fact , i recently read that on the stage , xxmaj ben xxmaj affleck has asked xxmaj bay whether it would be easier if they teach astronauts to drill , than drillers to becomes astronauts and xxmaj bay</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### uncomment below after you run above for the first time\n",
    "# data = load_data(path, f'{name}_databunch', bs=bs)\n",
    "# data.show_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### comment below after you run it for the first time\n",
    "learn = language_model_learner(data, AWD_LSTM, pretrained=True, drop_mult=0.30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "### comment below after you run it for the first time\n",
    "learn.lr_find()\n",
    "learn.recorder.plot(skip_end=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### comment below after you run it for the first time\n",
    "lr = 1e-3\n",
    "lr *= bs/48  # Scale learning rate by batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "### comment below after you run it for the first time\n",
    "learn.fit_one_cycle(1, lr*10, moms=(0.8,0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "### comment below after you run it for the first time\n",
    "learn.unfreeze()\n",
    "learn.fit_one_cycle(4, lr, moms=(0.8,0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "### comment below after you run it for the first time\n",
    "mdl_path = data_folder/'models'\n",
    "mdl_path.mkdir(exist_ok=True)\n",
    "learn.save(mdl_path/lm_fns[0], with_opt=False)\n",
    "learn.data.vocab.save(mdl_path/(lm_fns[1] + '.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "### uncomment below after you run it for the first time\n",
    "# learn = language_model_learner(data, AWD_LSTM, pretrained_fnames=lm_fns, drop_mult=0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Generation Methods & Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setup for text generation - prompts & number of words in each generated review\n",
    "TOKENS = [\"xxbos\",\"the\",\"this\",\"when\",\"i really\", \"you can\",\"if\", \"i was\", \"what\"]\n",
    "N_SENT = len(TOKENS)\n",
    "N_WORDS = 100 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(learn, text, n_words=1, no_unk=True, sep=' ', decoder=decode_spec_tokens):\n",
    "        \"Based on fastai implementation.\"\n",
    "        \"Return `text` and the `n_words` that come after\"\n",
    "        learn.model.reset()\n",
    "        xb,yb = learn.data.one_item(text)\n",
    "        new_idx = []\n",
    "        for _ in range(n_words):\n",
    "            res = learn.pred_batch(batch=(xb,yb))[0][-1]\n",
    "            res[learn.data.vocab.stoi[UNK]] = 0.\n",
    "            idx = torch.multinomial(res, 1).item()\n",
    "            new_idx.append(idx)\n",
    "            xb = xb.new_tensor([idx])[None]\n",
    "        return '[' + text + ']' + sep + sep.join(decoder(learn.data.vocab.textify(new_idx, sep=None)))\n",
    "    \n",
    "def beam_search(learn, text, n_words=1, top_k=10, beam_sz=1000, sep=' ', decoder=decode_spec_tokens):\n",
    "        \"Based on fastai implementation.\"\n",
    "        \"Return `text` and the `n_words` that come after\"\n",
    "        learn.model.reset()\n",
    "        learn.model.eval()\n",
    "        xb, yb = learn.data.one_item(text)\n",
    "        nodes = None\n",
    "        nodes = xb.clone()\n",
    "        scores = xb.new_zeros(1).float()\n",
    "        with torch.no_grad():\n",
    "            for k in progress_bar(range(n_words), leave=False):\n",
    "                out = F.log_softmax(learn.model(xb)[0][:,-1], dim=-1)\n",
    "                out[:,learn.data.vocab.stoi[UNK]] = -float('Inf')\n",
    "                values, indices = out.topk(top_k, dim=-1)\n",
    "                scores = (-values + scores[:,None]).view(-1)\n",
    "                indices_idx = torch.arange(0,nodes.size(0))[:,None].expand(nodes.size(0), top_k).contiguous().view(-1)\n",
    "                sort_idx = scores.argsort()[:beam_sz]\n",
    "                scores = scores[sort_idx]\n",
    "                nodes = torch.cat([nodes[:,None].expand(nodes.size(0),top_k,nodes.size(1)),\n",
    "                                indices[:,:,None].expand(nodes.size(0),top_k,1),], dim=2)\n",
    "                nodes = nodes.view(-1, nodes.size(2))[sort_idx]\n",
    "                learn.model[0].select_hidden(indices_idx[sort_idx])\n",
    "                xb = nodes[:,-1][:,None]\n",
    "        node_idx = torch.multinomial(torch.exp(-scores), 1).item()\n",
    "        return '[' + text + ']' + sep + sep.join(decoder(\n",
    "            learn.data.vocab.textify([i.item() for i in nodes[node_idx][1:] ], sep=None)))\n",
    "    \n",
    "def predict_topk(learn, text, n_words=1, k=5, sep=' ', decoder=decode_spec_tokens):\n",
    "        \"Based on paper.\"\n",
    "        \"Return `text` and the `n_words` that come after\"\n",
    "        learn.model.reset()\n",
    "        xb,yb = learn.data.one_item(text)\n",
    "        new_idx = []\n",
    "        for _ in range(n_words):\n",
    "            outp = learn.pred_batch(batch=(xb,yb))[0][-1]\n",
    "            outp[learn.data.vocab.stoi[UNK]] = 0.\n",
    "            probs = F.softmax(outp,dim=-1)\n",
    "            vals,idxs = probs.topk(k, dim=-1)\n",
    "            idx = idxs[torch.randint(k, (1,))]\n",
    "            new_idx.append(idx)\n",
    "            xb = xb.new_tensor([idx])[None]\n",
    "        return '[' + text + ']' + sep + sep.join(decoder(learn.data.vocab.textify(new_idx, sep=None)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. [xxbos] i 'm not sure how video games can ever get to a point in their 2007 video release , but of course that 's the option . Plausibility , thompson plot .... WHOEVER CARES TO MAKE THE MOVIE AS ARNIE GET THE SHOVED . Check Warren Beatty 's normal version of Burt Kennedy ... And the fat boy in Trick Or Treat ( 2001 ) is one likely the best Recent Michael Keaton movie\n",
      "\n",
      "2. [the] name of rehash Trek dubbing for east vs. west area , ACQUIRE : Wrecked by COFFIN aka REBELLIOUS ACTING WRITER , ED . i do n't know why i even laughed in this movie . FRONT LINE freaks out . Thank you Blues Brothers since i have no inclusion here that i watched that was but in essence , the cast are so bad that i actually tops my eyes when they went to work . So i ca n't imagine anyone that liked this pseudo\n",
      "\n",
      "3. [this] is the worst movie since RICKY SHOCK and Dream of This Grave since Hoods , the last . \n",
      " \n",
      "  now you can beat out just the worst bad movie from a feature film in your life . still not to make a movie i know that DD is the same that actually gave me nightmares , maybe they had just zemeckis seeing one of the worst movies i 've ever seen in my life . when i got this idea straight i rented it out , it was deep and cheesy and i\n",
      "\n",
      "4. [when] i saw this in On Demand , i went to see this sinking show with a touch of nostalgic monkey magic on lifetime ! i watched it again with great anticipation and was was impressed , its vague and inane writing ; it was predictable and my take down 's Spike Lee 's excellent voice - over adds over to my list of the worst quality films i have seen recently . My favorite character was when she said this does n't , trying to be funny with her caller . there was n't even\n",
      "\n",
      "5. [i really] loved this movie . It is very few things in store , i had to watch it all for the reasons i would have misunderstood it . i starring in that wonderful documentary starts with the beginning of the Return Of The King . i have seen Max at a Rock Concert and was alike i like this film . It was wonderful . The 1936 gimmick that led to the defeat of the Bad Guy in north of Paris was a fitting step for the end\n",
      "\n",
      "6. [you can] resist watching a film with feeling of torture - and me .. i can write so much from a seemingly random thing - and simply should do the whereas act of ' SNIPES ' that never broke even with my i stumbled onto the film . its not then another film or an action film , so it is pretty standard . \n",
      " \n",
      "  The biggest problem with swearing is that they are n't even adequate , it has to be clever . i mean it is the personification of violence . \n",
      " \n",
      "  the nudity is not worth reaching\n",
      "\n",
      "7. [if] you are familiar with Walter Matthau , they you will be stupid . this movie also relies on some weird fight scenes that will make you think something will be funny . but , in a way , do n't expect much spectacular animation and certainly not much of a plot . it 's a movie which makes me wonder if the characters are actually \" perfect . \" series movies were made several years before this one , but this movie also tries to be a good one . after being a kitchen cliché since Matthau\n",
      "\n",
      "8. [i was] browsing the local TV store number one and enough to invest attention that i loved how the showing up here appear to take place in THIRTIES Atlanta . i watched for over 10 minutes and i gather i 'm certain i had to catch it on TV ... who watches it anyway ? Well that 's the reason i did n't like it anyway ( although the quality might be a bit too obvious ) . At last it seems to go downhill immensely . As alcohol i grew older and started talking\n",
      "\n",
      "9. [what] a awful movie . Cleese is the only actor i can really connect with ( or maybe any of his other three movies are THE HOST ) , as does the truly legendary Sophia Loren . She has to be perfectly screen as a not - so - bright - light , unknown blond girl to begin with , barely succeeds in staying despite her needless troubles , the efforts of fans of HER MARTIAL ARTS , the yell of her - i chef , some b - movie , front\n"
     ]
    }
   ],
   "source": [
    "#greedy prediction\n",
    "print(\"\\n\\n\".join(str(i+1) + \". \" + predict(learn, TOKENS[i], N_WORDS) for i in range(N_SENT)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. [xxbos] xxbos This is one of the worst movies i have ever seen . The acting is terrible , the plot is non - existent , and the acting is terrible . The only good thing i can say about this movie is that it is so bad it 's good . If you want to see a good horror movie , do n't watch this . If you want to see a good horror movie , do n't watch this . If you want to see a good horror movie , do n't watch this\n",
      "\n",
      "2. [the] the first time i saw this movie , i thought it was the worst movie i have ever seen in my life . The first time i saw it , i thought it was the worst movie i have ever seen in my life . The first time i saw it , i thought it was the worst movie i have ever seen in my life . The first time i saw this movie , i thought it was the worst movie i have ever seen in my life . It was so bad that i had\n",
      "\n",
      "3. [this] this is one of the worst movies i have ever seen . the acting is terrible , the plot is ridiculous , and the acting is terrible . the only reason i gave it a 2 instead of a 1 instead of a 1 is because i am a big fan of b - movies , and this is one of the worst movies i have ever seen . the only reason i gave it a 2 instead of a 1 instead of a 1 is because i am a huge fan of b - movies , but this one is\n",
      "\n",
      "4. [when] when i first heard about this movie , i thought it was going to be a good movie . i was wrong . i was n't expecting much from this movie , but i was pleasantly surprised . The acting was good , the story was good , and the story was well written . The acting was n't bad , but it was n't as bad as i thought it would be . It was n't as bad as i thought it would be , but it was n't as bad as i thought it was .\n",
      "\n",
      "5. [i really] i really do n't know what to say about this movie . It 's not a bad movie . It 's not funny . It 's not funny . It 's not funny . It 's not funny . It 's not funny . It 's not funny . It 's not funny . It 's not funny . It 's not funny . It 's not funny . It 's not funny . It 's not funny . It is n't funny . It 's not\n",
      "\n",
      "6. [you can] you can say that this is one of the worst movies i have ever seen in my life . i do n't think i 've ever seen a worse movie in my life . This is one of the worst movies i have ever seen . The only reason i gave it a 2 instead of a 1 instead of a 1 is because it was so bad . The only reason i gave it a 2 instead of a 1 instead of a 1 was because it was so bad . If you want to see a\n",
      "\n",
      "7. [if] if you have n't seen this movie , do yourself a favor and do n't waste your time or money on it . If you have n't seen it , do n't waste your time or money on it . Do n't waste your time . Do n't waste your time . Do n't waste your time . Do n't waste your time . Do n't waste your time . Do n't waste your time . Do n't waste your time . Do n't waste your time . Do n't waste\n",
      "\n",
      "8. [i was] i was lucky enough to see this movie at the Toronto International Film Festival . It is one of the best movies i have seen in a long time . The acting is superb , the story is great , and the acting is superb . This movie is a must - see . xxbos This is one of the worst movies i have seen in a long time . The acting is terrible , the plot is non - existent , and the acting is terrible . The only reason i\n",
      "\n",
      "9. [what] what a waste of time and money . This movie is a waste of time and money . The only reason i gave it a 2 instead of a 1 instead of a 1 instead of a 1 is because the movie is so bad it 's good . The acting is bad , the story is stupid and the acting is terrible . The only good thing i can say about this movie is that it 's so bad it 's good . xxbos This is one of the worst movies i 've ever seen\n"
     ]
    }
   ],
   "source": [
    "#beam-search prediction\n",
    "print(\"\\n\\n\".join(str(i+1) + \". \" + beam_search(learn, TOKENS[i], N_WORDS, top_k=6, beam_sz=20) for i in range(N_SENT)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. [xxbos] i 'm sure there were many things wrong for the movie : the first , that was n't really a movie at least a half hour of its duration . Then , after watching it , we had some fun with the story of how the President and Mrs. President were going together . But that does n't really matter as the movie did . i think that George and his family did an excellent , entertaining and entertaining thing , as we were told that it would have to do more . i\n",
      "\n",
      "2. [the] film was very interesting and the story is very well developed and well - developed . i liked John and John and the film is very well acted but Robert and his friends have no idea how to make an entertaining and entertaining story of love , family & the family and the relationships between the parents and kids , it does have some good moments . The acting , however was pretty weak and the direction by the John was also a disappointment as he has a very weak script to tell .\n",
      "\n",
      "3. [this] movie had so much promise but it did nt even get any better from this point . it was a total waste to be on , and it 's the first time you will have to be a fan . i am so glad i did , and this was just another of the many things that i would like , but if you are into the Dark , and do n't think that the original Crow : Darkness is the movie you need , this movie was a waste . i am a Christian so\n",
      "\n",
      "4. [when] i saw this film , my girlfriend said , she was n't impressed , so i decided it might just look bad , but i 'm wrong and it is a terrible movie ! ! i think the director should 've been shot and then shot in Iraq . the film looks and looks great but it 's not really a great piece of cinema , and the film is just too long to make it even a 1 minute movie , and that 's not enough of an explanation to anyone who actually watches the entire picture .\n",
      "\n",
      "5. [i really] enjoyed the American film . \n",
      " \n",
      "  i was n't sure what it 's about to happen , but what was i talking of ? ? ? i do n't understand the point . \n",
      " \n",
      "  the plot is pretty good , and it was n't too much to say that it 's a Hollywood movie but it does make me want more of James and his family . \n",
      " \n",
      "  this is not an action / adventure , it has a very serious plot . It was well done but i think this movie could not get better\n",
      "\n",
      "6. [you can] not understand how a lot can go down as bad as this . This film does a terrible disservice for any film . \n",
      " \n",
      "  i was really surprised by the film . the plot was a lot of fun . a lot more people are killed off . the acting , direction , script and story is all top - grade ( the only thing i did n't get was that there is one ) and that it does not have the budget . it does give the impression you can do a good horror movie but not in\n",
      "\n",
      "7. [if] you want an interesting story , check Dark 's work on HBO . the story line will make a lot more money than most other films , it will keep the viewer in mind and to watch a film that has something different than the first one to watch and it has its good parts . \n",
      " \n",
      "  the acting in the second film was good , especially by the lead character ( who played his part very very well and was n't really a character either , i was very interested , he was very well acted )\n",
      "\n",
      "8. [i was] n't a fan . MY God . But it is the most interesting and well written Christmas film i had to pay to watch in the theatre , and it really did make me cry , i was in my late twenties . a good movie with good performances and a good storyline ! \n",
      " \n",
      "  xxbos i saw This is the best of the three films that were released , which was one in my humble view , the others being \" E.T. \" and the TV - Film series ( which\n",
      "\n",
      "9. [what] a terrible movie . the script , the acting ( and the writing ) was awful . it had the feel to it and the plot , the plot was just a joke of sorts . \n",
      " \n",
      "  i was expecting some decent actors in this one , i guess the acting could not get worse as they went through all these problems with it and i could not believe it was made up for it to . i would not have given a 1 out out for it because i was a bit surprised by this . xxbos \" a\n"
     ]
    }
   ],
   "source": [
    "#top-k prediction\n",
    "print(\"\\n\\n\".join(str(i+1) + \". \" + predict_topk(learn, TOKENS[i], N_WORDS) for i in range(N_SENT)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
